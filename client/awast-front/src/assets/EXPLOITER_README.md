# AWAST Exploitation Engine Documentation

The **AI-Powered Exploitation Engine** is a core component of AWAST designed to actively verify vulnerabilities found by scanners like OWASP ZAP. Instead of relying purely on static payload lists, it uses **Large Language Models (LLMs)** to dynamically analyze contexts, parse error messages, and bypass filters (WAFs) in real-time.

## üöÄ Key Features and LLM Capabilities

The `ExploiterService` implements 6 advanced AI-driven exploitation techniques to confirm vulnerabilities with high certainty:

| Technique | Description |
| :--- | :--- |
| **Context-Aware XSS** | Injects a canary string (`AWAST_TEST_STRING`), extracts the exact HTML block where it is reflected, and asks the LLM to generate a custom payload designed specifically to break out of that HTML context without being caught. |
| **WAF Bypassing** | If an injection attempt results in an HTTP `403/401 Not Authorized` or `406 Not Acceptable`, the service passes the blocked payload to the LLM to analyze the context and apply obfuscation/encoding to bypass the WAF. |
| **SSTI Engine Identification** | Parses HTTP `500 Internal Server Error` responses. By analyzing the stack trace syntax, the LLM identifies the target template engine (e.g., Jinja2, Twig) and generates a precise Remote Code Execution (RCE) payload. |
| **API Parameter Guessing** | Used for IDOR and Mass Assignment. Scans JSON API endpoints and uses the LLM to hallucinate hidden parameter keys (like `"role": "admin"`, `"is_admin": true`) to test for authorization flaws. |
| **Prompt Injection / AI Jailbreak** | If the target URL is an LLM application, the Exploiter will actively test system prompt leaks and jailbreak instructions. |
| **Error-Based SQL Analysis** | Parses raw database error strings to inform the LLM of the backend DBMS. The LLM then structures the exact SQL payload needed for exploitation. |

---

## üì° API Endpoints

The Exploiter Controller exposes two primary endpoints:

### 1. `POST /exploiter/run`

Initiates the payload generation and verification runner against a confirmed URL.

**Request Body Schema (`ExploiterRequestBody`):**
```json
{
  "target": "http://example.com/api/user/1",
  "params": "id",
  "vuln_type": "SQL Injection",
  "cookies": {
    "PHPSESSID": "abc123...",
    "security": "low"
  },
  "method": "POST",
  "ws_id": "e9b1cd48-23fc-4928"
}
```

**Response Data (`status: "confirmed"`):**
If the service successfully exploits the vulnerability, it returns all information needed to reproduce the attack.
```json
{
  "status": "confirmed",
  "vuln_type": "SQL Injection",
  "target": "http://example.com/api/user/1",
  "parameter": "id",
  "working_payload": "' OR 1=1 --",
  "tried_payloads": ["1' OR '1'='1", "1; DROP TABLE users;", "' OR 1=1 --"],
  "proof": "–ù–∞–π–¥–µ–Ω –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —É—è–∑–≤–∏–º–æ—Å—Ç–∏: syntax error",
  "curl": "curl -s -X POST -d 'id=' OR 1=1 --' http://example.com/api/user/1",
  "message": "–£—è–∑–≤–∏–º–æ—Å—Ç—å —É—Å–ø–µ—à–Ω–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞ –∏ —ç–∫—Å–ø–ª—É–∞—Ç–∏—Ä–æ–≤–∞–Ω–∞!"
}
```

**Response Data (`status: "potential"`):**
If the engine fails to definitively confirm an exploit, it returns the generated payload attempts for manual review:
```json
{
  "status": "potential",
  "message": "–ù–∏ –æ–¥–∏–Ω payload –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª. –í–æ–∑–º–æ–∂–Ω–æ, –Ω—É–∂–Ω–∞ —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞.",
  "tried_payloads": [...]
}
```

---

### 2. `WS /exploiter/ws/{ws_id}`
*(Real-Time Exploitation Logging)*

Because LLM generation and network fuzzing are slow, the API leverages WebSockets to stream execution state perfectly formatted for frontend terminal visuals.

**Frontend Connection Example:**
```javascript
// 1. Generate unique Session ID
const wsId = crypto.randomUUID();

// 2. Connect to WS
const socket = new WebSocket(`ws://localhost:8000/exploiter/ws/${wsId}`);

// 3. Listen to categorized events
socket.onmessage = (event) => {
    const data = JSON.parse(event.data);
    switch (data.type) {
        case 'info':
            console.log(`[SYSTEM] ${data.message}`);
            break;
        case 'log':
            console.log(`> ${data.message}`);
            break;
        case 'attack':
            console.log(`[ATTACK] Trying payload: ${data.payload}`);
            break;
        case 'success':
            console.warn(`[VULNERABLE] ${data.message}`);
            break;
        case 'failed':
            console.error(`[FAILED] payload failed validation.`);
            break;
    }
};

// 4. Send POST request with the attached wsId
await axios.post('/exploiter/run', { ..., ws_id: wsId });
```

---

## üõ†Ô∏è Internal Architecture Flow

1. **Initialization**: The frontend calls `/exploiter/run` with target parameters.
2. **Session Persistence**: The user provides session cookies directly (e.g., `PHPSESSID`, `security`) in the request body. No browser-based login is needed.
3. **LLM Generation**: The system pings the configured `llm_service` endpoint asynchronously (`ask_for_payloads()`), prompting the AI to generate an initial batch of 5 targeted payloads.
4. **Execution Loop**: The async `try_exploit` function begins mapping payloads against the parameter.
5. **Dynamic Feedback (The AI Loop)**:
   - If a `403 WAF Error` is hit, it pauses the loop and requests an obfuscated payload from the LLM.
   - If a `200 OK` HTML is received during an XSS test, it extracts the reflection context and requests an escape payload from the LLM.
6. **Assertion**: The HTTP response is parsed against known vulnerability markers (`self.success_indicators`).
7. **Resolution**: Broadcasts to the WebSocket and returns the final JSON.

## Environment Variables

Ensure these exist for the Exploiter Engine to run:
* `LLM_URL` - Endpoint to your local Ollama or cloud provider inference URL.
* `MODEL` - Required model ID (e.g. `llama3` or `mistral`).
